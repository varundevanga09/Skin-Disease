{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import image as mp_image\n",
    "import seaborn as sns\n",
    "\n",
    "# Required magic to display matplotlib plots in notebooks\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dermatofibroma', 'melanoma', 'pigmented benign keratosis', 'seborrheic keratosis', 'squamous cell carcinoma', 'vascular lesion']\n"
     ]
    }
   ],
   "source": [
    "# The images are in a folder named 'input/natural-images/natural_images'\n",
    "training_folder_name = 'Skin Disease Classification/Train'\n",
    "\n",
    "# All images are 128x128 pixels\n",
    "img_size = (128,128)\n",
    "\n",
    "# The folder contains a subfolder for each class of shape\n",
    "classes = sorted(os.listdir(training_folder_name))\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting torch\n",
      "  Downloading torch-2.3.0-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.18.0-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: filelock in d:\\anaconda\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in d:\\anaconda\\lib\\site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: sympy in d:\\anaconda\\lib\\site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in d:\\anaconda\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in d:\\anaconda\\lib\\site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in d:\\anaconda\\lib\\site-packages (from torch) (2023.10.0)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in d:\\anaconda\\lib\\site-packages (from torchvision) (10.2.0)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch)\n",
      "  Using cached tbb-2021.12.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in d:\\anaconda\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in d:\\anaconda\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Downloading torch-2.3.0-cp311-cp311-win_amd64.whl (159.8 MB)\n",
      "   ---------------------------------------- 0.0/159.8 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/159.8 MB 4.3 MB/s eta 0:00:38\n",
      "   ---------------------------------------- 1.0/159.8 MB 13.0 MB/s eta 0:00:13\n",
      "    --------------------------------------- 3.1/159.8 MB 25.0 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 6.1/159.8 MB 35.2 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 9.2/159.8 MB 39.1 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 11.3/159.8 MB 50.4 MB/s eta 0:00:03\n",
      "   --- ------------------------------------ 13.8/159.8 MB 59.8 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 16.7/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   ---- ----------------------------------- 16.7/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 21.5/159.8 MB 54.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 24.4/159.8 MB 54.4 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 27.1/159.8 MB 73.1 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 29.6/159.8 MB 65.2 MB/s eta 0:00:02\n",
      "   ------- -------------------------------- 31.1/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 31.1/159.8 MB 59.5 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 32.3/159.8 MB 36.4 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 34.1/159.8 MB 34.4 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 36.0/159.8 MB 32.7 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 37.6/159.8 MB 31.1 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 38.5/159.8 MB 31.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 38.5/159.8 MB 31.2 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 38.5/159.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 38.5/159.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 38.5/159.8 MB 23.4 MB/s eta 0:00:06\n",
      "   --------- ------------------------------ 38.6/159.8 MB 18.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 38.6/159.8 MB 18.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 38.6/159.8 MB 15.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 38.6/159.8 MB 15.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 38.6/159.8 MB 15.2 MB/s eta 0:00:08\n",
      "   --------- ------------------------------ 38.6/159.8 MB 13.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 38.6/159.8 MB 13.1 MB/s eta 0:00:10\n",
      "   --------- ------------------------------ 38.6/159.8 MB 11.5 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 38.6/159.8 MB 11.5 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 38.6/159.8 MB 11.5 MB/s eta 0:00:11\n",
      "   --------- ------------------------------ 38.6/159.8 MB 10.2 MB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 43.8/159.8 MB 11.5 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 44.7/159.8 MB 11.5 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 46.5/159.8 MB 11.3 MB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 47.7/159.8 MB 11.1 MB/s eta 0:00:11\n",
      "   ------------ --------------------------- 49.3/159.8 MB 46.9 MB/s eta 0:00:03\n",
      "   ------------ --------------------------- 50.3/159.8 MB 40.9 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 52.2/159.8 MB 36.4 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 53.6/159.8 MB 29.7 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 55.4/159.8 MB 31.2 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 56.8/159.8 MB 32.8 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 58.0/159.8 MB 32.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 59.6/159.8 MB 34.4 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 60.1/159.8 MB 34.6 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 60.5/159.8 MB 28.5 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 60.7/159.8 MB 27.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 60.7/159.8 MB 27.3 MB/s eta 0:00:04\n",
      "   --------------- ------------------------ 61.7/159.8 MB 21.8 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 64.0/159.8 MB 23.4 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 65.1/159.8 MB 22.6 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 65.7/159.8 MB 21.1 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 66.8/159.8 MB 19.8 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 68.0/159.8 MB 19.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 69.0/159.8 MB 19.3 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 70.4/159.8 MB 21.1 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 71.4/159.8 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 72.8/159.8 MB 25.2 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 74.0/159.8 MB 22.6 MB/s eta 0:00:04\n",
      "   ------------------ --------------------- 75.6/159.8 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 76.6/159.8 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 77.8/159.8 MB 27.3 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 79.1/159.8 MB 27.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 80.4/159.8 MB 27.3 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 81.7/159.8 MB 26.2 MB/s eta 0:00:03\n",
      "   -------------------- ------------------- 83.2/159.8 MB 27.3 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 84.4/159.8 MB 26.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 85.3/159.8 MB 26.2 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 86.9/159.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 88.4/159.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 90.0/159.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ---------------------- ----------------- 91.3/159.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 92.8/159.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 93.2/159.8 MB 27.3 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 94.3/159.8 MB 28.4 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 29.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 21.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 21.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 21.8 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 14.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 14.6 MB/s eta 0:00:05\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 12.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 12.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.3/159.8 MB 12.6 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 11.1 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 9.8 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 9.8 MB/s eta 0:00:07\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 8.8 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 8.8 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 8.8 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 8.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 8.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 8.1 MB/s eta 0:00:08\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 7.4 MB/s eta 0:00:09\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 6.8 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 6.8 MB/s eta 0:00:10\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 6.3 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 6.3 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 6.3 MB/s eta 0:00:11\n",
      "   ----------------------- ---------------- 95.4/159.8 MB 5.9 MB/s eta 0:00:11\n",
      "   ------------------------ --------------- 96.6/159.8 MB 5.7 MB/s eta 0:00:12\n",
      "   ------------------------- -------------- 102.8/159.8 MB 6.3 MB/s eta 0:00:10\n",
      "   -------------------------- ------------- 103.9/159.8 MB 6.4 MB/s eta 0:00:09\n",
      "   -------------------------- ------------- 105.3/159.8 MB 6.3 MB/s eta 0:00:09\n",
      "   -------------------------- ------------ 106.6/159.8 MB 54.7 MB/s eta 0:00:01\n",
      "   -------------------------- ------------ 108.1/159.8 MB 46.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------ 109.4/159.8 MB 38.5 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 110.7/159.8 MB 32.7 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 111.8/159.8 MB 28.4 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 113.0/159.8 MB 27.3 MB/s eta 0:00:02\n",
      "   --------------------------- ----------- 113.9/159.8 MB 26.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 115.1/159.8 MB 25.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 116.0/159.8 MB 24.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 116.8/159.8 MB 24.2 MB/s eta 0:00:02\n",
      "   ---------------------------- ---------- 118.0/159.8 MB 24.2 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 119.2/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 120.1/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 121.1/159.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ----------------------------- --------- 122.3/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 123.3/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 124.4/159.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 125.6/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------ -------- 126.8/159.8 MB 23.4 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 127.4/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 128.4/159.8 MB 21.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 129.5/159.8 MB 21.8 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 130.4/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 22.6 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 17.7 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 14.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 14.9 MB/s eta 0:00:02\n",
      "   ------------------------------- ------- 131.0/159.8 MB 12.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.0/159.8 MB 12.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.0/159.8 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.0/159.8 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.0/159.8 MB 11.3 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.0/159.8 MB 10.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 131.0/159.8 MB 10.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 131.0/159.8 MB 9.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.0/159.8 MB 9.1 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.0/159.8 MB 8.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.0/159.8 MB 8.3 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.1/159.8 MB 7.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.1/159.8 MB 7.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.1/159.8 MB 7.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------- 131.1/159.8 MB 7.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 7.0 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 6.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 6.5 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 6.1 MB/s eta 0:00:05\n",
      "   -------------------------------- ------- 131.1/159.8 MB 5.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 131.1/159.8 MB 5.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 131.1/159.8 MB 5.6 MB/s eta 0:00:06\n",
      "   -------------------------------- ------- 131.1/159.8 MB 5.3 MB/s eta 0:00:06\n",
      "   --------------------------------- ------ 135.7/159.8 MB 5.6 MB/s eta 0:00:05\n",
      "   ----------------------------------- ---- 140.0/159.8 MB 6.2 MB/s eta 0:00:04\n",
      "   ----------------------------------- ---- 140.9/159.8 MB 6.2 MB/s eta 0:00:04\n",
      "   ---------------------------------- ---- 141.7/159.8 MB 65.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 142.5/159.8 MB 54.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 143.5/159.8 MB 40.9 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 144.4/159.8 MB 34.6 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 145.3/159.8 MB 29.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 146.2/159.8 MB 27.3 MB/s eta 0:00:01\n",
      "   ----------------------------------- --- 147.4/159.8 MB 24.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 148.5/159.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 149.5/159.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 150.7/159.8 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 151.7/159.8 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 152.9/159.8 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 154.0/159.8 MB 21.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 155.1/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  156.4/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  157.3/159.8 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  158.3/159.8 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.4/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  159.8/159.8 MB 23.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 159.8/159.8 MB 2.8 MB/s eta 0:00:00\n",
      "Downloading torchvision-0.18.0-cp311-cp311-win_amd64.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.1/1.2 MB 34.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.2/1.2 MB 18.8 MB/s eta 0:00:00\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.12.0-py3-none-win_amd64.whl (286 kB)\n",
      "Installing collected packages: tbb, intel-openmp, mkl, torch, torchvision\n",
      "Successfully installed intel-openmp-2021.4.0 mkl-2021.4.0 tbb-2021.12.0 torch-2.3.0 torchvision-0.18.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/torch/\n",
      "WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /simple/torch/\n",
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'ProtocolError('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))': /packages/2a/b7/a3cf5fd40334b9785cc83ee0c96b50603026eb3aa70210a33729018e7029/torch-2.3.0-cp311-cp311-win_amd64.whl.metadata\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported - ready to use PyTorch 2.3.0+cpu\n"
     ]
    }
   ],
   "source": [
    "# Import PyTorch libraries\n",
    "!pip install torch torchvision\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print(\"Libraries imported - ready to use PyTorch\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# function to resize image\n",
    "def resize_image(src_image, size=(128,128), bg_color=\"white\"): \n",
    "    from PIL import Image, ImageOps \n",
    "    \n",
    "    # resize the image so the longest dimension matches our target size\n",
    "    src_image.thumbnail(size, Image.ANTIALIAS)\n",
    "    \n",
    "    # Create a new square background image\n",
    "    new_image = Image.new(\"RGB\", size, bg_color)\n",
    "    \n",
    "    # Paste the resized image into the center of the square background\n",
    "    new_image.paste(src_image, (int((size[0] - src_image.size[0]) / 2), int((size[1] - src_image.size[1]) / 2)))\n",
    "  \n",
    "    # return the resized image\n",
    "    return new_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming images...\n",
      "processing folder dermatofibroma\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'PIL.Image' has no attribute 'ANTIALIAS'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 31\u001b[0m\n\u001b[0;32m     29\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(file_path)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Create a resized version and save it\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m resized_image \u001b[38;5;241m=\u001b[39m \u001b[43mresize_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m saveAs \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(saveFolder, file_name)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m#print(\"writing \" + saveAs)\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 8\u001b[0m, in \u001b[0;36mresize_image\u001b[1;34m(src_image, size, bg_color)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image, ImageOps \n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# resize the image so the longest dimension matches our target size\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m src_image\u001b[38;5;241m.\u001b[39mthumbnail(size, \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mANTIALIAS\u001b[49m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Create a new square background image\u001b[39;00m\n\u001b[0;32m     11\u001b[0m new_image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mnew(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m, size, bg_color)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'PIL.Image' has no attribute 'ANTIALIAS'"
     ]
    }
   ],
   "source": [
    "training_folder_name = 'Skin Disease Classification/Train'\n",
    "\n",
    "# New location for the resized images\n",
    "train_folder = 'data/train'\n",
    "\n",
    "\n",
    "# Create resized copies of all of the source images\n",
    "size = (128,128)\n",
    "\n",
    "# Create the output folder if it doesn't already exist\n",
    "if os.path.exists(train_folder):\n",
    "    shutil.rmtree(train_folder)\n",
    "\n",
    "# Loop through each subfolder in the input folder\n",
    "print('Transforming images...')\n",
    "for root, folders, files in os.walk(training_folder_name):\n",
    "    for sub_folder in folders:\n",
    "        print('processing folder ' + sub_folder)\n",
    "        # Create a matching subfolder in the output dir\n",
    "        saveFolder = os.path.join(train_folder,sub_folder)\n",
    "        if not os.path.exists(saveFolder):\n",
    "            os.makedirs(saveFolder)\n",
    "        # Loop through the files in the subfolder\n",
    "        file_names = os.listdir(os.path.join(root,sub_folder))\n",
    "        for file_name in file_names:\n",
    "            # Open the file\n",
    "            file_path = os.path.join(root,sub_folder, file_name)\n",
    "            #print(\"reading \" + file_path)\n",
    "            image = Image.open(file_path)\n",
    "            # Create a resized version and save it\n",
    "            resized_image = resize_image(image, size)\n",
    "            saveAs = os.path.join(saveFolder, file_name)\n",
    "            #print(\"writing \" + saveAs)\n",
    "            resized_image.save(saveAs)\n",
    "\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path):\n",
    "    import torch\n",
    "    import torchvision\n",
    "    import torchvision.transforms as transforms\n",
    "    # Load all the images\n",
    "    transformation = transforms.Compose([\n",
    "        # Randomly augment the image data\n",
    "            # Random horizontal flip\n",
    "        transforms.RandomHorizontalFlip(0.5),\n",
    "            # Random vertical flip\n",
    "        transforms.RandomVerticalFlip(0.3),\n",
    "        # transform to tensors\n",
    "        transforms.ToTensor(),\n",
    "        # Normalize the pixel values (in R, G, and B channels)\n",
    "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "    ])\n",
    "\n",
    "    # Load all of the images, transforming them\n",
    "    full_dataset = torchvision.datasets.ImageFolder(\n",
    "        root=data_path,\n",
    "        transform=transformation\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # Split into training (70% and testing (30%) datasets)\n",
    "    train_size = int(0.7 * len(full_dataset))\n",
    "    test_size = len(full_dataset) - train_size\n",
    "    \n",
    "    # use torch.utils.data.random_split for training/test split\n",
    "    train_dataset, test_dataset = torch.utils.data.random_split(full_dataset, [train_size, test_size])\n",
    "    \n",
    "    # define a loader for the training data we can iterate through in 50-image batches\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "    \n",
    "    # define a loader for the testing data we can iterate through in 50-image batches\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=50,\n",
    "        num_workers=0,\n",
    "        shuffle=False\n",
    "    )\n",
    "        \n",
    "    return train_loader, test_loader\n",
    "\n",
    "\n",
    "\n",
    "# Recall that we have resized the images and saved them into\n",
    "train_folder = 'data/train'\n",
    "\n",
    "# Get the iterative dataloaders for test and training data\n",
    "train_loader, test_loader = load_dataset(train_folder)\n",
    "batch_size = train_loader.batch_size\n",
    "print(\"Data loaders ready to read\", train_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    # Set the model to training mode\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    print(\"Epoch:\", epoch)\n",
    "    # Process the images in batches\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        # Use the CPU or GPU as appropriate\n",
    "        # Recall that GPU is optimized for the operations we are dealing with\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Reset the optimizer\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Push the data forward through the model layers\n",
    "        output = model(data)\n",
    "        \n",
    "        # Get the loss\n",
    "        loss = loss_criteria(output, target)\n",
    "\n",
    "        # Keep a running total\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Print metrics so we see some progress\n",
    "        print('\\tTraining batch {} Loss: {:.6f}'.format(batch_idx + 1, loss.item()))\n",
    "            \n",
    "    # return average loss for the epoch\n",
    "    avg_loss = train_loss / (batch_idx+1)\n",
    "    print('Training set: Average loss: {:.6f}'.format(avg_loss))\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, device, test_loader):\n",
    "    # Switch the model to evaluation mode (so we don't backpropagate or drop)\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        batch_count = 0\n",
    "        for data, target in test_loader:\n",
    "            batch_count += 1\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            \n",
    "            # Get the predicted classes for this batch\n",
    "            output = model(data)\n",
    "            \n",
    "            # Calculate the loss for this batch\n",
    "            test_loss += loss_criteria(output, target).item()\n",
    "            \n",
    "            # Calculate the accuracy for this batch\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            correct += torch.sum(target==predicted).item()\n",
    "\n",
    "    # Calculate the average loss and total accuracy for this epoch\n",
    "    avg_loss = test_loss / batch_count\n",
    "    print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        avg_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "    \n",
    "    # return average loss for the epoch\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use an \"Adam\" optimizer to adjust weights\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Specify the loss criteria\n",
    "loss_criteria = nn.CrossEntropyLoss()\n",
    "\n",
    "# Track metrics in these arrays\n",
    "epoch_nums = []\n",
    "training_loss = []\n",
    "validation_loss = []\n",
    "\n",
    "\n",
    "epochs = 10\n",
    "print('Training on', device)\n",
    "for epoch in range(1, epochs + 1):\n",
    "        train_loss = train(model, device, train_loader, optimizer, epoch)\n",
    "        test_loss = test(model, device, test_loader)\n",
    "        epoch_nums.append(epoch)\n",
    "        training_loss.append(train_loss)\n",
    "        validation_loss.append(test_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Loss History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "plt.plot(epoch_nums, training_loss)\n",
    "plt.plot(epoch_nums, validation_loss)\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['training', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Defining Labels and Predictions\n",
    "truelabels = []\n",
    "predictions = []\n",
    "model.eval()\n",
    "print(\"Getting predictions from test set...\")\n",
    "for data, target in test_loader:\n",
    "    for label in target.data.numpy():\n",
    "        truelabels.append(label)\n",
    "    for prediction in model(data).data.numpy().argmax(1):\n",
    "        predictions.append(prediction) \n",
    "\n",
    "# Plot the confusion matrix\n",
    "cm = confusion_matrix(truelabels, predictions)\n",
    "tick_marks = np.arange(len(classes))\n",
    "\n",
    "df_cm = pd.DataFrame(cm, index = classes, columns = classes)\n",
    "plt.figure(figsize = (7,7))\n",
    "sns.heatmap(df_cm, annot=True, cmap=plt.cm.Blues, fmt='g')\n",
    "plt.xlabel(\"Predicted Shape\", fontsize = 20)\n",
    "plt.ylabel(\"True Shape\", fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Fine Tuning TL & GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential, layers\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import LeakyReLU\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils.vis_utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from keras.models import Sequential\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import PIL\n",
    "import time\n",
    "\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resizinig all the images to (224,224)\n",
    "IMAGE_SIZE = [224,224]\n",
    "\n",
    "train_path1 = 'Skin Disease Classification/Train'\n",
    "test_path1 = 'Skin Disease Classification/Test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling all the images between 0 to 1\n",
    "\n",
    "train_datagen1 = ImageDataGenerator(rescale = 1./255, shear_range=0.2, zoom_range=0.2, horizontal_flip=False)\n",
    "\n",
    "# Performing only scaling on the test dataset\n",
    "\n",
    "test_datagen1 = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set1 = train_datagen1.flow_from_directory(train_path1,\n",
    "                                              target_size=(224,224),\n",
    "                                              batch_size=32,\n",
    "                                              class_mode = 'categorical')\n",
    "\n",
    "test_set1 = test_datagen1.flow_from_directory(test_path1,\n",
    "                                            target_size=(224,224),\n",
    "                                            batch_size=32,\n",
    "                                            class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Flatten, Input, Lambda\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "inc=InceptionResNetV2(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNet, MobileNetV2\n",
    "mob = MobileNet(input_shape = IMAGE_SIZE + [3], weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1= Flatten()(mob.output)\n",
    "prediction1 = Dense(6, activation='softmax')(x1)\n",
    "model12 = Model(inputs = mob.inputs, outputs = prediction1)\n",
    "model12.summary()\n",
    "model12.compile(loss = 'categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = model12.fit_generator(train_set1, validation_data=test_set1, epochs=5, steps_per_epoch=len(train_set1), validation_steps=len(test_set1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=r1\n",
    "plt.figure(figsize=(20,10))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.suptitle('Optimizer : adam', fontsize=10)\n",
    "plt.ylabel('Loss', fontsize=16)\n",
    "plt.plot(x.history['loss'], label='Training Loss')\n",
    "plt.plot(x.history['val_loss'], label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.ylabel('Accuracy', fontsize=16)\n",
    "plt.plot(x.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(x.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model12.save('model1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
